# Week 2: Regression and model validation
This data has 183 observations for 60 variables. The variables inlcude several questions about different topics along with Age, combination score for Attitude, gender and total points.Today, I read the data from URL web page, combined the questions related to deep, surf and stra and created new columns for each. Then, I made a new dataset including only 7 variables:age, gender, attitude, points, deep, surf, stra. I scaled the combined variables to original scale by dividing each to the number of their questions. I excluded Points>0 values and the Newdata now has 166 observations of 7 variables. I saved the data into csv format using write.csv function. I read the Newdata again and explored the dimensions and structure of the data to check whether everything was done right.

Now, let's do the analysis!
First, reading the data **(read.table function)** and exploring the dimensions **(dim function)** and structure **(str function)**. It seems right as the Newdata I hade made in data wrnagling process should have 166 observations for 7 variables.These 7 variables are: age, gender, attitude, points, deep, surf, stra. Age, attitude and Points are interval variables, gender is a two-level nominal variables and deep, surf, stra are numerical variables. 
I used **pairs(Newdata)** function to draw a plot of the relationships between all the variables. It draws 6 plots for each of the 7 variables. From what I see, most of the varaible pairs have positive relationships except for deep&surf, which shows a negative relationship.The most positive relationships seem to be between attitude&points and deep&stra because the plot dots are the most tightly gathered around the imaginary line.

Now, variables summaries!
I used **summary(Newdata$variable)** function to explore the variable summaries. This function shows distribution of categorical variables and mean, min and max values, median (2nd quartile) and quartile 1&3 for the continuous variables. For example, age has a minimum value of 17 and a mean of 25.5. Distribution of gender is: 110 females and 56 males and so on.

Now, multiple regression analysis!
I chose three independent variables to see how they regress against the dependent variable "Points". According to scatterplot matrices, I chose **Attitude**, **deep** and **stra** as independent variables. I used the function **lm(Points~ Attitude + stra + deep, data = Newdata)** for the regression model. The I used **summary()** function to study the summary of the regression model. Attitude had a significant relationship with Points (p-values<0.001), but the other two independent variables did not show significant relationships. This model had a multiple R-squared of 0.20 which means about 20% of the variation in the depednent variable "Points" is caused by the three indepedent variables. for the next regression model I removed those two insignificant indepedent variables variables. According to the model summary, this new regression model had a multiple R-squared of 0.19 which means about 19% of the variation in the depednent variable "Points" is caused by the indepedent variable "Attitude". These models highlight the important explanatory role of Attitude in Points. 

Now, model diagnostics!
I used the **plot(my_regressionmodel2, which = c(1,2,5))** function to draw three diagnostic plots. The first plot, Residuals vs Fitted, tests the validity of model assumptions. It confirms the linearity assumption and that the regression model is linear. The second plot. QQ plot, tests whethet the errors are normally distributed and it confirms the normal distribution because the dots are well accumulated around the regression line. The last plot shows leverage level of observations and it seems there is a regular leverage with no outstanding outlier. 

#Reading data
library(dplyr)
Faran <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)

#Exploring data
str(Faran)
dim(Faran)

#deep, surf, stra questions
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")

#deep, surf, stra columns
deep_columns <- select(Faran,one_of(deep_questions))
surf_columns <- select(Faran, one_of(surface_questions))
stra_columns <- select(Faran, one_of(strategic_questions))
Faran$deep <- rowMeans(deep_columns)
Faran$surf <- rowMeans(surf_columns)
Faran$stra <- rowMeans(stra_columns)
keep <- c("Age", "gender", "Attitude", "Points", "deep", "surf", "stra")
Newdata <- select(Faran, one_of(keep))

#deep, surf, stra scaling
deep_scaled <- Faran$deep/12
surf_scaled <- Faran$surf/12
stra_sclaed <- Faran$stra/8

#Excluding data
Newdata <- filter(Newdata, Points > 0)

#Saving data
write.csv(Newdata, file = "Newdata.csv")

#Reading new data and exploring it
read.csv("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
dim(Newdata)
str(Newdata)

#Plot matrix
pairs(Newdata
)
#Regression model and its summary
my_regressionmodel <- lm(Points ~ Attitude + stra + deep, data = Newdata)
summary(my_regressionmodel)

#Regression model 2 excluding nonsignificant explanators
my_regressionmodel2 <- lm(Points ~ Attitude, data = Newdata)
summary(my_regressionmodel2)

#Summary of variables
summary(Newdata$deep)
summary(Newdata$surf)
summary(Newdata$stra)
summary(Newdata$Age)
summary(Newdata$gender)
summary(Newdata$Attitude)
summary(Newdata$Points)

#Regression diagnostic plots
plot(my_regressionmodel2, which = c(1,2,5))